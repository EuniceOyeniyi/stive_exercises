{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfroming classification on car dataset using decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset complete info:'https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data'\n",
    "## Attribute information\n",
    "1. Class Values:  unacc, acc, good, vgood\n",
    "\n",
    "### Attributes:\n",
    "\n",
    "2. buying: vhigh, high, med, low.\n",
    "3. maint: vhigh, high, med, low.\n",
    "4. doors: 2, 3, 4, 5more.\n",
    "5. persons: 2, 4, more.\n",
    "6. lug_boot: small, med, big.\n",
    "7. safety: low, med, high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loding and visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data ='https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2     3      4     5      6\n",
       "0     vhigh  vhigh      2     2  small   low  unacc\n",
       "1     vhigh  vhigh      2     2  small   med  unacc\n",
       "2     vhigh  vhigh      2     2  small  high  unacc\n",
       "3     vhigh  vhigh      2     2    med   low  unacc\n",
       "4     vhigh  vhigh      2     2    med   med  unacc\n",
       "...     ...    ...    ...   ...    ...   ...    ...\n",
       "1723    low    low  5more  more    med   med   good\n",
       "1724    low    low  5more  more    med  high  vgood\n",
       "1725    low    low  5more  more    big   low  unacc\n",
       "1726    low    low  5more  more    big   med   good\n",
       "1727    low    low  5more  more    big  high  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(car_data,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column =['buying','maint','doors','persons','lug_boot','safety','Acceptabilty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Acceptabilty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety Acceptabilty\n",
       "0  vhigh  vhigh     2       2    small    low        unacc\n",
       "1  vhigh  vhigh     2       2    small    med        unacc\n",
       "2  vhigh  vhigh     2       2    small   high        unacc\n",
       "3  vhigh  vhigh     2       2      med    low        unacc\n",
       "4  vhigh  vhigh     2       2      med    med        unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(car_data,names=column)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   buying        1728 non-null   object\n",
      " 1   maint         1728 non-null   object\n",
      " 2   doors         1728 non-null   object\n",
      " 3   persons       1728 non-null   object\n",
      " 4   lug_boot      1728 non-null   object\n",
      " 5   safety        1728 non-null   object\n",
      " 6   Acceptabilty  1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for col_name in df.columns:\n",
    "#         plt.figure()\n",
    "#         plt.hist(df[col_name])\n",
    "#         plt.title(col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low' 'med' 'high' 'vhigh']\n"
     ]
    }
   ],
   "source": [
    "buying = df.buying.unique()[::-1]\n",
    "print(buying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low' 'med' 'high' 'vhigh']\n"
     ]
    }
   ],
   "source": [
    "maint = df.maint.unique()[::-1]\n",
    "print(maint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '3' '4' '5more']\n"
     ]
    }
   ],
   "source": [
    "door = df.doors.unique()\n",
    "print(door)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '4' 'more']\n"
     ]
    }
   ],
   "source": [
    "person = df.persons.unique()\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small' 'med' 'big']\n"
     ]
    }
   ],
   "source": [
    "boot = df.lug_boot.unique()\n",
    "print(boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety',\n",
       "       'Acceptabilty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe =df.safety.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept = df.Acceptabilty.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OrdinalEncoder(categories = [buying,maint,door,person,boot,safe,accept])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder(categories=[array(['low', 'med', 'high', 'vhigh'], dtype=object),\n",
       "                           array(['low', 'med', 'high', 'vhigh'], dtype=object),\n",
       "                           array(['2', '3', '4', '5more'], dtype=object),\n",
       "                           array(['2', '4', 'more'], dtype=object),\n",
       "                           array(['small', 'med', 'big'], dtype=object),\n",
       "                           array(['low', 'med', 'high'], dtype=object),\n",
       "                           array(['unacc', 'acc', 'vgood', 'good'], dtype=object)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df= oe.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = new_df[:, :-1], new_df[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualizing the first decision tree in the forest\n",
    "# index = 0\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# tree.plot_tree(clf.estimators_[index],\n",
    "#                    feature_names = new_df.columns, \n",
    "#                    class_names=[\"unacc\", \"acc\", \"good\", \"vgood\"],\n",
    "#                    filled = True,);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       3., 0., 0., 0., 1., 0., 0., 0., 3., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 2., 1., 0., 0.,\n",
       "       0., 0., 2., 3., 0., 0., 0., 0., 0., 0., 1., 1., 2., 1., 0., 1., 0.,\n",
       "       3., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 3., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 2., 0., 0., 0., 0., 3., 0., 0., 1., 0., 0., 1., 2.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 2., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       2., 1., 0., 0., 0., 0., 1., 0., 3., 2., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 3., 1., 2., 0., 2., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 2., 0., 0.,\n",
       "       1., 0., 0., 0., 2., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 2., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       3., 1., 1., 1., 0., 1., 0., 3., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 2., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 3., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 2., 1., 1., 0., 1., 3.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 2., 0., 1., 0., 1.,\n",
       "       0., 1., 3., 3., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       3., 1., 0., 0., 1., 0., 0., 0., 3., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 3., 1., 0., 0., 0., 2.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 2., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction =clf.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking accurary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T430\\anaconda3\\envs\\strive\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x12c496ab2b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(clf, X_test, y_test, display_labels=[\"unacc\", \"acc\", \"good\", \"vgood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99       363\n",
      "         1.0       0.92      0.97      0.95       115\n",
      "         2.0       0.90      0.90      0.90        20\n",
      "         3.0       0.95      0.86      0.90        21\n",
      "\n",
      "    accuracy                           0.97       519\n",
      "   macro avg       0.94      0.93      0.93       519\n",
      "weighted avg       0.97      0.97      0.97       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# printing the report\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to check the best estimators using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[500,1000,1500,1728], 'criterion': ( 'gini' , 'entropy') , 'max_depth' :[5,8,12],'max_features':('auto',  'log2')  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(clf, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': [5, 8, 12],\n",
       "                         'max_features': ('auto', 'log2'),\n",
       "                         'n_estimators': [500, 1000, 1500, 1728]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9586365350982475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=12, n_estimators=1728,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = grid_search.best_estimator_\n",
    "print(grid_search.best_score_)\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.002383</td>\n",
       "      <td>0.132486</td>\n",
       "      <td>0.077752</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.896694</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.893310</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.846462</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.148708</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.896694</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.893310</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.954380</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>0.246648</td>\n",
       "      <td>0.024686</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.895789</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.206023</td>\n",
       "      <td>0.025291</td>\n",
       "      <td>0.258042</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.894136</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.914236</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.075154</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.896694</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.893310</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.850260</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.148309</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.896694</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.893310</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.765096</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.222063</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.895789</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.339743</td>\n",
       "      <td>0.177523</td>\n",
       "      <td>0.266435</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.904564</td>\n",
       "      <td>0.894136</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.970002</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.081350</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.929461</td>\n",
       "      <td>0.952834</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.935607</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.155105</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.952011</td>\n",
       "      <td>0.015438</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.886622</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.243049</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.953664</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.324952</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.279627</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.953664</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.080934</td>\n",
       "      <td>0.099780</td>\n",
       "      <td>0.094142</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.929461</td>\n",
       "      <td>0.952834</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.975582</td>\n",
       "      <td>0.085598</td>\n",
       "      <td>0.154106</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.952011</td>\n",
       "      <td>0.015438</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.876028</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.240851</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.953664</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.326751</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.263638</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.953664</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.022769</td>\n",
       "      <td>0.036406</td>\n",
       "      <td>0.090345</td>\n",
       "      <td>0.020816</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.955324</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.987375</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.172893</td>\n",
       "      <td>0.034084</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.956984</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.132669</td>\n",
       "      <td>0.141182</td>\n",
       "      <td>0.240652</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.954497</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.464465</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.265037</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.954497</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.988192</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.080949</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.955324</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.995371</td>\n",
       "      <td>0.016850</td>\n",
       "      <td>0.156303</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.956984</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.036329</td>\n",
       "      <td>0.046736</td>\n",
       "      <td>0.241851</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.954497</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.565604</td>\n",
       "      <td>0.240141</td>\n",
       "      <td>0.278827</td>\n",
       "      <td>0.022499</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.954497</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.022512</td>\n",
       "      <td>0.077152</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.921488</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.917012</td>\n",
       "      <td>0.908196</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.856256</td>\n",
       "      <td>0.017546</td>\n",
       "      <td>0.149309</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.906550</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.785683</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>0.235654</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.921488</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.909029</td>\n",
       "      <td>0.014481</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.267986</td>\n",
       "      <td>0.135809</td>\n",
       "      <td>0.262038</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.921488</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.921162</td>\n",
       "      <td>0.907373</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.987191</td>\n",
       "      <td>0.055260</td>\n",
       "      <td>0.084549</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.921488</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.917012</td>\n",
       "      <td>0.908196</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.858654</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.146710</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.906550</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.786683</td>\n",
       "      <td>0.046226</td>\n",
       "      <td>0.221264</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.921488</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.909029</td>\n",
       "      <td>0.014481</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.251396</td>\n",
       "      <td>0.059765</td>\n",
       "      <td>0.268035</td>\n",
       "      <td>0.029493</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.921488</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.921162</td>\n",
       "      <td>0.907373</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.080335</td>\n",
       "      <td>0.094192</td>\n",
       "      <td>0.085147</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.929752</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.950351</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.090712</td>\n",
       "      <td>0.274565</td>\n",
       "      <td>0.165497</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.950351</td>\n",
       "      <td>0.017227</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.822262</td>\n",
       "      <td>0.111706</td>\n",
       "      <td>0.248047</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.951178</td>\n",
       "      <td>0.016501</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.478057</td>\n",
       "      <td>0.440141</td>\n",
       "      <td>0.275431</td>\n",
       "      <td>0.016307</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.948699</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.057148</td>\n",
       "      <td>0.085445</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.929752</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.950351</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.000366</td>\n",
       "      <td>0.016790</td>\n",
       "      <td>0.199077</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.950351</td>\n",
       "      <td>0.017227</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.104486</td>\n",
       "      <td>0.216210</td>\n",
       "      <td>0.246848</td>\n",
       "      <td>0.029553</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.951178</td>\n",
       "      <td>0.016501</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.620386</td>\n",
       "      <td>0.230911</td>\n",
       "      <td>0.280426</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.948699</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.014811</td>\n",
       "      <td>0.093838</td>\n",
       "      <td>0.075154</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.957810</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.950398</td>\n",
       "      <td>0.157860</td>\n",
       "      <td>0.182488</td>\n",
       "      <td>0.061031</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.956977</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.695938</td>\n",
       "      <td>0.029979</td>\n",
       "      <td>0.226461</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>0.957807</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.262590</td>\n",
       "      <td>0.229999</td>\n",
       "      <td>0.252445</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.958637</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.889852</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.957810</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.784501</td>\n",
       "      <td>0.017817</td>\n",
       "      <td>0.143311</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.956977</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.677750</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>0.228259</td>\n",
       "      <td>0.026454</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>0.957807</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3.110484</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.250445</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>1728</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'max...</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.971074</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.958637</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.002383      0.132486         0.077752        0.003653   \n",
       "1        1.846462      0.021383         0.148708        0.002134   \n",
       "2        2.954380      0.115375         0.246648        0.024686   \n",
       "3        3.206023      0.025291         0.258042        0.003967   \n",
       "4        0.914236      0.013430         0.075154        0.001938   \n",
       "5        1.850260      0.021938         0.148309        0.000799   \n",
       "6        2.765096      0.009510         0.222063        0.004066   \n",
       "7        3.339743      0.177523         0.266435        0.027315   \n",
       "8        0.970002      0.009804         0.081350        0.006402   \n",
       "9        1.935607      0.014776         0.155105        0.002784   \n",
       "10       2.886622      0.015046         0.243049        0.028600   \n",
       "11       3.324952      0.014442         0.279627        0.025537   \n",
       "12       1.080934      0.099780         0.094142        0.017669   \n",
       "13       1.975582      0.085598         0.154106        0.001165   \n",
       "14       2.876028      0.012820         0.240851        0.027047   \n",
       "15       3.326751      0.035885         0.263638        0.001719   \n",
       "16       1.022769      0.036406         0.090345        0.020816   \n",
       "17       1.987375      0.010607         0.172893        0.034084   \n",
       "18       3.132669      0.141182         0.240652        0.014775   \n",
       "19       3.464465      0.019364         0.265037        0.001939   \n",
       "20       0.988192      0.007596         0.080949        0.001789   \n",
       "21       1.995371      0.016850         0.156303        0.001356   \n",
       "22       3.036329      0.046736         0.241851        0.016078   \n",
       "23       3.565604      0.240141         0.278827        0.022499   \n",
       "24       0.943819      0.022512         0.077152        0.004487   \n",
       "25       1.856256      0.017546         0.149309        0.001199   \n",
       "26       2.785683      0.013770         0.235654        0.026332   \n",
       "27       3.267986      0.135809         0.262038        0.017012   \n",
       "28       0.987191      0.055260         0.084549        0.013726   \n",
       "29       1.858654      0.017759         0.146710        0.001470   \n",
       "30       2.786683      0.046226         0.221264        0.002058   \n",
       "31       3.251396      0.059765         0.268035        0.029493   \n",
       "32       1.080335      0.094192         0.085147        0.007301   \n",
       "33       2.090712      0.274565         0.165497        0.020241   \n",
       "34       2.822262      0.111706         0.248047        0.025214   \n",
       "35       3.478057      0.440141         0.275431        0.016307   \n",
       "36       1.057148      0.085445         0.085747        0.011644   \n",
       "37       2.000366      0.016790         0.199077        0.083385   \n",
       "38       3.104486      0.216210         0.246848        0.029553   \n",
       "39       3.620386      0.230911         0.280426        0.018724   \n",
       "40       1.014811      0.093838         0.075154        0.002924   \n",
       "41       1.950398      0.157860         0.182488        0.061031   \n",
       "42       2.695938      0.029979         0.226461        0.024189   \n",
       "43       3.262590      0.229999         0.252445        0.012963   \n",
       "44       0.889852      0.003199         0.072754        0.000748   \n",
       "45       1.784501      0.017817         0.143311        0.000490   \n",
       "46       2.677750      0.010626         0.228259        0.026454   \n",
       "47       3.110484      0.024048         0.250445        0.002058   \n",
       "\n",
       "   param_criterion param_max_depth param_max_features param_n_estimators  \\\n",
       "0             gini               5               auto                500   \n",
       "1             gini               5               auto               1000   \n",
       "2             gini               5               auto               1500   \n",
       "3             gini               5               auto               1728   \n",
       "4             gini               5               log2                500   \n",
       "5             gini               5               log2               1000   \n",
       "6             gini               5               log2               1500   \n",
       "7             gini               5               log2               1728   \n",
       "8             gini               8               auto                500   \n",
       "9             gini               8               auto               1000   \n",
       "10            gini               8               auto               1500   \n",
       "11            gini               8               auto               1728   \n",
       "12            gini               8               log2                500   \n",
       "13            gini               8               log2               1000   \n",
       "14            gini               8               log2               1500   \n",
       "15            gini               8               log2               1728   \n",
       "16            gini              12               auto                500   \n",
       "17            gini              12               auto               1000   \n",
       "18            gini              12               auto               1500   \n",
       "19            gini              12               auto               1728   \n",
       "20            gini              12               log2                500   \n",
       "21            gini              12               log2               1000   \n",
       "22            gini              12               log2               1500   \n",
       "23            gini              12               log2               1728   \n",
       "24         entropy               5               auto                500   \n",
       "25         entropy               5               auto               1000   \n",
       "26         entropy               5               auto               1500   \n",
       "27         entropy               5               auto               1728   \n",
       "28         entropy               5               log2                500   \n",
       "29         entropy               5               log2               1000   \n",
       "30         entropy               5               log2               1500   \n",
       "31         entropy               5               log2               1728   \n",
       "32         entropy               8               auto                500   \n",
       "33         entropy               8               auto               1000   \n",
       "34         entropy               8               auto               1500   \n",
       "35         entropy               8               auto               1728   \n",
       "36         entropy               8               log2                500   \n",
       "37         entropy               8               log2               1000   \n",
       "38         entropy               8               log2               1500   \n",
       "39         entropy               8               log2               1728   \n",
       "40         entropy              12               auto                500   \n",
       "41         entropy              12               auto               1000   \n",
       "42         entropy              12               auto               1500   \n",
       "43         entropy              12               auto               1728   \n",
       "44         entropy              12               log2                500   \n",
       "45         entropy              12               log2               1000   \n",
       "46         entropy              12               log2               1500   \n",
       "47         entropy              12               log2               1728   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.896694   \n",
       "1   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.896694   \n",
       "2   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.900826   \n",
       "3   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.900826   \n",
       "4   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.896694   \n",
       "5   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.896694   \n",
       "6   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.900826   \n",
       "7   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.900826   \n",
       "8   {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.954545   \n",
       "9   {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.950413   \n",
       "10  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.954545   \n",
       "11  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.954545   \n",
       "12  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.954545   \n",
       "13  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.950413   \n",
       "14  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.954545   \n",
       "15  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.954545   \n",
       "16  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.962810   \n",
       "17  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.962810   \n",
       "18  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.958678   \n",
       "19  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.958678   \n",
       "20  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.962810   \n",
       "21  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.962810   \n",
       "22  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.958678   \n",
       "23  {'criterion': 'gini', 'max_depth': 12, 'max_fe...           0.958678   \n",
       "24  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.913223   \n",
       "25  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.904959   \n",
       "26  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.904959   \n",
       "27  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.904959   \n",
       "28  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.913223   \n",
       "29  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.904959   \n",
       "30  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.904959   \n",
       "31  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.904959   \n",
       "32  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.958678   \n",
       "33  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.962810   \n",
       "34  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.962810   \n",
       "35  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.962810   \n",
       "36  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.958678   \n",
       "37  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.962810   \n",
       "38  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.962810   \n",
       "39  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.962810   \n",
       "40  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.966942   \n",
       "41  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.962810   \n",
       "42  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.966942   \n",
       "43  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.966942   \n",
       "44  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.966942   \n",
       "45  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.962810   \n",
       "46  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.966942   \n",
       "47  {'criterion': 'entropy', 'max_depth': 12, 'max...           0.966942   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.880165           0.913223           0.871901   \n",
       "1            0.884298           0.909091           0.871901   \n",
       "2            0.880165           0.917355           0.876033   \n",
       "3            0.876033           0.913223           0.876033   \n",
       "4            0.880165           0.913223           0.871901   \n",
       "5            0.884298           0.909091           0.871901   \n",
       "6            0.880165           0.917355           0.876033   \n",
       "7            0.876033           0.913223           0.876033   \n",
       "8            0.966942           0.975207           0.938017   \n",
       "9            0.962810           0.975207           0.938017   \n",
       "10           0.966942           0.975207           0.938017   \n",
       "11           0.966942           0.975207           0.938017   \n",
       "12           0.966942           0.975207           0.938017   \n",
       "13           0.962810           0.975207           0.938017   \n",
       "14           0.966942           0.975207           0.938017   \n",
       "15           0.966942           0.975207           0.938017   \n",
       "16           0.958678           0.971074           0.942149   \n",
       "17           0.954545           0.971074           0.946281   \n",
       "18           0.954545           0.971074           0.946281   \n",
       "19           0.954545           0.971074           0.946281   \n",
       "20           0.958678           0.971074           0.942149   \n",
       "21           0.954545           0.971074           0.946281   \n",
       "22           0.954545           0.971074           0.946281   \n",
       "23           0.954545           0.971074           0.946281   \n",
       "24           0.884298           0.921488           0.904959   \n",
       "25           0.880165           0.917355           0.904959   \n",
       "26           0.884298           0.921488           0.909091   \n",
       "27           0.884298           0.921488           0.904959   \n",
       "28           0.884298           0.921488           0.904959   \n",
       "29           0.880165           0.917355           0.904959   \n",
       "30           0.884298           0.921488           0.909091   \n",
       "31           0.884298           0.921488           0.904959   \n",
       "32           0.966942           0.971074           0.929752   \n",
       "33           0.962810           0.966942           0.933884   \n",
       "34           0.962810           0.966942           0.938017   \n",
       "35           0.954545           0.966942           0.933884   \n",
       "36           0.966942           0.971074           0.929752   \n",
       "37           0.962810           0.966942           0.933884   \n",
       "38           0.962810           0.966942           0.938017   \n",
       "39           0.954545           0.966942           0.933884   \n",
       "40           0.954545           0.971074           0.946281   \n",
       "41           0.962810           0.971074           0.946281   \n",
       "42           0.958678           0.971074           0.946281   \n",
       "43           0.958678           0.971074           0.946281   \n",
       "44           0.954545           0.971074           0.946281   \n",
       "45           0.962810           0.971074           0.946281   \n",
       "46           0.958678           0.971074           0.946281   \n",
       "47           0.958678           0.971074           0.946281   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.904564         0.893310        0.015269               45  \n",
       "1            0.904564         0.893310        0.013614               45  \n",
       "2            0.904564         0.895789        0.015504               41  \n",
       "3            0.904564         0.894136        0.015318               43  \n",
       "4            0.904564         0.893310        0.015269               45  \n",
       "5            0.904564         0.893310        0.013614               45  \n",
       "6            0.904564         0.895789        0.015504               41  \n",
       "7            0.904564         0.894136        0.015318               43  \n",
       "8            0.929461         0.952834        0.017137               21  \n",
       "9            0.933610         0.952011        0.015438               23  \n",
       "10           0.933610         0.953664        0.016051               17  \n",
       "11           0.933610         0.953664        0.016051               17  \n",
       "12           0.929461         0.952834        0.017137               21  \n",
       "13           0.933610         0.952011        0.015438               23  \n",
       "14           0.933610         0.953664        0.016051               17  \n",
       "15           0.933610         0.953664        0.016051               17  \n",
       "16           0.941909         0.955324        0.011566               11  \n",
       "17           0.950207         0.956984        0.008932                7  \n",
       "18           0.941909         0.954497        0.010181               13  \n",
       "19           0.941909         0.954497        0.010181               13  \n",
       "20           0.941909         0.955324        0.011566               11  \n",
       "21           0.950207         0.956984        0.008932                7  \n",
       "22           0.941909         0.954497        0.010181               13  \n",
       "23           0.941909         0.954497        0.010181               13  \n",
       "24           0.917012         0.908196        0.013125               35  \n",
       "25           0.925311         0.906550        0.015297               39  \n",
       "26           0.925311         0.909029        0.014481               33  \n",
       "27           0.921162         0.907373        0.013664               37  \n",
       "28           0.917012         0.908196        0.013125               35  \n",
       "29           0.925311         0.906550        0.015297               39  \n",
       "30           0.925311         0.909029        0.014481               33  \n",
       "31           0.921162         0.907373        0.013664               37  \n",
       "32           0.925311         0.950351        0.019107               27  \n",
       "33           0.925311         0.950351        0.017227               27  \n",
       "34           0.925311         0.951178        0.016501               25  \n",
       "35           0.925311         0.948699        0.016325               31  \n",
       "36           0.925311         0.950351        0.019107               27  \n",
       "37           0.925311         0.950351        0.017227               27  \n",
       "38           0.925311         0.951178        0.016501               25  \n",
       "39           0.925311         0.948699        0.016325               31  \n",
       "40           0.950207         0.957810        0.009599                3  \n",
       "41           0.941909         0.956977        0.011029                9  \n",
       "42           0.946058         0.957807        0.010306                5  \n",
       "43           0.950207         0.958637        0.009459                1  \n",
       "44           0.950207         0.957810        0.009599                3  \n",
       "45           0.941909         0.956977        0.011029                9  \n",
       "46           0.946058         0.957807        0.010306                5  \n",
       "47           0.950207         0.958637        0.009459                1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying LDA before Random forest to see if has any effect on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "lda = LinearDiscriminantAnalysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_lda= lda.fit_transform(X_train_scaled,y_train)\n",
    "X_test_scaled_lda= lda.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier()\n",
    "clf2.fit(X_train_scaled_lda, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 4, 1, 2, 1, 1, 1, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3,\n",
       "       1, 2, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 4, 1, 1, 1, 3, 2, 1, 1,\n",
       "       3, 2, 1, 4, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 3, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       4, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2,\n",
       "       3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 4, 1, 2, 1, 2, 1, 1, 1,\n",
       "       1, 4, 3, 2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 3, 3, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 3, 1,\n",
       "       2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 4, 1, 1, 1, 2, 1, 2, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 4, 1, 2, 1, 2, 1, 4, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 4, 1, 2, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 2,\n",
       "       1, 2, 1, 1, 1, 1, 1, 4, 4, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2,\n",
       "       1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf2.predict(X_test_scaled_lda)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439306358381503"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(X_test_scaled_lda,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA before Random forest to see if has any effect on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_pca= pca.fit_transform(X_train_scaled,y_train)\n",
    "X_test_scaled_pca= pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = RandomForestClassifier()\n",
    "clf3.fit(X_train_scaled_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516377649325626"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(X_test_scaled_lda,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_confusion_matrix(clf, X_test, y_test, display_labels=[\"unacc\", \"acc\", \"good\", \"vgood\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b30284c3eb2fe4bedcae5b4d3ef6c8cdca82eb3ff0361126b1f813dcb02e6084"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('strive')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
